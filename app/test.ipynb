{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-12 15:54:11.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msupport_files.graph_connection\u001b[0m:\u001b[36mneo4j_connection\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mSuccessfully established Neo4j connection.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from support_files.graph_connection import neo4j_connection\n",
    "import json\n",
    "graph = neo4j_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccasary packages\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import Callable\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from support_files.tool_execution import *\n",
    "from support_files.lead_agent import lead_assistant_runnable, lead_agent_tool,safe_tool, sensitive_tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "ist_timezone = timezone(\"Asia/Kolkata\")\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from typing import Annotated, Literal, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Push or pop the state.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str\n",
    "    dialog_state: Annotated[\n",
    "        list[\n",
    "            Literal[\n",
    "                \"assistant\",\n",
    "                \"lead_existance_verification\",\n",
    "                \"lead_creation\",\n",
    "            ]\n",
    "        ],\n",
    "        update_dialog_stack,\n",
    "    ]\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "            # If the LLM happens to return an empty response, we will re-prompt it\n",
    "            # for an actual response.\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "class CompleteOrEscalate(BaseModel):\n",
    "    \"\"\"A tool to mark the current task as completed and/or to escalate control of the dialog to the main assistant,\n",
    "    who can re-route the dialog based on the user's needs.\"\"\"\n",
    "\n",
    "    cancel: bool = True\n",
    "    reason: str\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"User changed their mind about the current task.\",\n",
    "            },\n",
    "            \"example 2\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"I have fully completed the task.\",\n",
    "            },\n",
    "            \"example 3\": {\n",
    "                \"cancel\": False,\n",
    "                \"reason\": \"I need to search the emails for more information.\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)\n",
    "\n",
    "class Lead_assistant(BaseModel):\n",
    "    \"\"\"Transfer work to a specialized assistant to handle the lead relevant details.\"\"\"\n",
    "\n",
    "    location: str = Field(\n",
    "        description=\"The location where the user wants create or udate or delete the lead.\"\n",
    "    )\n",
    "    name: str = Field(description=\"Name of the customer.\")\n",
    "    phone: str = Field(description=\"Phone number of the customer.\")\n",
    "    email: str = Field(description=\"Email of the customer.\")\n",
    "    civilID: str = Field(description=\"Civil ID of the customer.\")\n",
    "\n",
    "    request: str = Field(\n",
    "        description=\"Any additional information or requests from the user regarding the create or udate or delete the lead.\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"name\": \"Chandru\",\n",
    "                \"phone\": \"+91 8124832683\",\n",
    "                \"email\": \"chandruganeshan@gmail.com\",\n",
    "                \"civilID\": \"986534567893\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "def create_entry_node(assistant_name: str, new_dialog_state: str) -> Callable:\n",
    "    def entry_node(state: State) -> dict:\n",
    "        tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=f\"The assistant is now the {assistant_name}. Reflect on the above conversation between the host assistant and the user.\"\n",
    "                    f\" The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are {assistant_name},\"\n",
    "                    \" and the booking, update, other other action is not complete until after you have successfully invoked the appropriate tool.\"\n",
    "                    \" If the user changes their mind or needs help for other tasks, call the CompleteOrEscalate function to let the primary host assistant take control.\"\n",
    "                    \" Do not mention who you are - just act as the proxy for the assistant.\",\n",
    "                    tool_call_id=tool_call_id,\n",
    "                )\n",
    "            ],\n",
    "            \"dialog_state\": new_dialog_state,\n",
    "        }\n",
    "\n",
    "    return entry_node\n",
    "\n",
    "\n",
    "model = ChatGroq(model=\"llama3-70b-8192\",temperature=0)\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for Automotive Industry.\"\n",
    "            \"Your primary role is search leads, customer details, test drive details and other customer required deatils.\"\n",
    "            \"If the customer wants to create or update or delete the lead, book test drive, create a quotation, \"\n",
    "            \"delegate the task to appropriate specialized assistants by invoking corresponding tools. You are not able to make these type of changes yourself\"\n",
    "            \"Only the specialized assistants are given permission to do this for the user.\"\n",
    "            \"The user is not aware of the different specialized assistants, so do not mention them; just quietly delegate through function calls. \"\n",
    "            \"Provide detailed information to the customer, and always double-check the database before concluding that information is unavailable. \"\n",
    "            \"When searching, be persistent. Expand your query bounds if the first search returns no results.\"\n",
    "            \"If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\nCurrent time: {time}.\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now(ist_timezone).isoformat())\n",
    "\n",
    "\n",
    "primary_assistant_runnable = primary_assistant_prompt | model.bind_tools([Lead_assistant])\n",
    "def pop_dialog_state(state: State) -> dict:\n",
    "    \"\"\"Pop the dialog stack and return to the main assistant.\n",
    "\n",
    "    This lets the full graph explicitly track the dialog flow and delegate control\n",
    "    to specific sub-graphs.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    if state[\"messages\"][-1].tool_calls:\n",
    "        # Note: Doesn't currently handle the edge case where the llm performs parallel tool calls\n",
    "        messages.append(\n",
    "            ToolMessage(\n",
    "                content=\"Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\n",
    "        \"dialog_state\": \"pop\",\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "# Compile graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"enter_lead_assistant\",create_entry_node(\"Lead Assistant\", \"lead_agent\"))\n",
    "builder.add_node(\"lead_agent\", Assistant(lead_assistant_runnable))\n",
    "builder.add_edge(\"enter_lead_assistant\", \"lead_agent\")\n",
    "\n",
    "builder.add_node(\n",
    "    \"lead_assistant_safe_tools\",\n",
    "    create_tool_node_with_fallback(safe_tool)\n",
    ")\n",
    "\n",
    "builder.add_node(\n",
    "    \"lead_assistant_sensitive_tools\",\n",
    "    create_tool_node_with_fallback(sensitive_tool)\n",
    ")\n",
    "\n",
    "builder.add_node(\"primary_assistant\", Assistant(primary_assistant_runnable))\n",
    "builder.add_edge(START, \"primary_assistant\")\n",
    "\n",
    "builder.add_node(\"leave_skill\", pop_dialog_state)\n",
    "builder.add_edge(\"leave_skill\", \"primary_assistant\")\n",
    "builder.add_edge(\"primary_assistant\", \"enter_lead_assistant\")\n",
    "\n",
    "def route_lead_assistant(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"lead_assistant_safe_tools\",\n",
    "    \"lead_assistant_sensitive_tools\",\n",
    "    \"leave_skill\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    did_cancel = any(tc[\"name\"] == CompleteOrEscalate.__name__ for tc in tool_calls)\n",
    "    if did_cancel:\n",
    "        return \"leave_skill\"\n",
    "    safe_toolnames = [t.name for t in safe_tool]\n",
    "    if all(tc[\"name\"] in safe_toolnames for tc in tool_calls):\n",
    "        return \"lead_assistant_safe_tools\"\n",
    "    return \"lead_assistant_sensitive_tools\"\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "def route_primary_assistant(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"primary_assistant_tools\",\n",
    "    \"enter_lead_assistant\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    if tool_calls:\n",
    "        if tool_calls[0][\"name\"] == Lead_assistant.__name__:\n",
    "            return \"enter_lead_assistant\"\n",
    "        return \"primary_assistant_tools\"\n",
    "    raise ValueError(\"Invalid route\")\n",
    "\n",
    "\n",
    "# The assistant can route to one of the delegated assistants,\n",
    "# directly use a tool, or directly respond to the user\n",
    "builder.add_conditional_edges(\n",
    "    \"primary_assistant\",\n",
    "    route_primary_assistant,\n",
    "    {\n",
    "        \"enter_lead_assistant\": \"enter_lead_assistant\",\n",
    "        \"primary_assistant_tools\": \"primary_assistant_tools\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "builder.add_edge(\"primary_assistant_tools\", \"primary_assistant\")\n",
    "\n",
    "def route_to_workflow(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"primary_assistant\",\n",
    "    \"lead_agent\",\n",
    "]:\n",
    "    \"\"\"If we are in a delegated state, route directly to the appropriate assistant.\"\"\"\n",
    "    dialog_state = state.get(\"dialog_state\")\n",
    "    if not dialog_state:\n",
    "        return \"primary_assistant\"\n",
    "    return dialog_state[-1]\n",
    "\n",
    "\n",
    "# builder.add_conditional_edges(\"fetch_user_info\", route_to_workflow)\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "builder.add_edge(\"lead_assistant_safe_tools\", \"lead_agent\")\n",
    "builder.add_edge(\"lead_assistant_sensitive_tools\", \"lead_agent\")\n",
    "builder.add_conditional_edges(\"lead_agent\",route_lead_assistant)\n",
    "\n",
    "# Compile graph\n",
    "memory = MemorySaver()\n",
    "part_4_graph = builder.compile(checkpointer=memory,interrupt_before=[\"lead_assistant_sensitive_tool\"],)\n",
    "\n",
    "part_4_graph.get_graph(xray=True).draw_mermaid_png(output_file_path=\"part_4_graph.png\")\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": 1,\n",
    "    }\n",
    "}\n",
    "\n",
    "_printed = set()\n",
    "while True:\n",
    "    print(State[\"messages\"])\n",
    "    question = input(\"Ask question: \")\n",
    "    events = part_4_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_lead(name: str = None, email: str = None, phone: str = None, civil_id: str = None):\n",
    "    \"\"\"\n",
    "    Verify the existence of the Customer in our Database.\n",
    "    \n",
    "    Parameters:\n",
    "    - name: Customer's name (mandatory).\n",
    "    - email: Customer's email (optional).\n",
    "    - phone: Customer's phone (optional).\n",
    "    - civil_id: Customer's civil ID (optional).\n",
    "    \n",
    "    Returns:\n",
    "    - Customer details if the lead exists.\n",
    "    - Message indicating whether the customer exists or not.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Base query for fully verified search\n",
    "    query = \"\"\"\n",
    "    MATCH (l:Lead)\n",
    "    WHERE toLower(l.name) = toLower($name)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Conditions for additional fields\n",
    "    conditions = []\n",
    "    if phone:\n",
    "        conditions.append(\"l.phone_number = $phone\")\n",
    "    if civil_id:\n",
    "        conditions.append(\"l.civil_id = $civil_id\")\n",
    "    if email:\n",
    "        conditions.append(\"l.email = $email\")\n",
    "    \n",
    "    if conditions:\n",
    "        query += \" AND \" + \" AND \".join(conditions)\n",
    "\n",
    "    query += \"\"\"\n",
    "    RETURN l.name AS lead_name, l.phone_number AS phone_number, l.civil_id AS civil_id, l.email AS email, l.id AS lead_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the fully verified query\n",
    "    verified_result = graph.query(query, {\n",
    "        'name': name,\n",
    "        'phone': phone,\n",
    "        'civil_id': civil_id,\n",
    "        'email': email\n",
    "    })\n",
    "    \n",
    "    # Check if fully verified result exists\n",
    "    print(verified_result)\n",
    "    if verified_result:\n",
    "        return f\"A customer named '{name}' already exists in our system. Would you like to continue with this existing customer, or should I create a new customer?\"\n",
    "    else:        \n",
    "\n",
    "        cypher_queries = []\n",
    "        semi_verified_result = []\n",
    "\n",
    "        # Prepare similarity query for the name\n",
    "        name_query = \"\"\"\n",
    "                    MATCH (c:Lead)\n",
    "                    WITH c, apoc.text.levenshteinSimilarity(toLower(c.name), toLower($name)) AS similarity_score\n",
    "                    WHERE similarity_score > 0.8\n",
    "                    RETURN c.name AS customer_name, c.phone_number AS phone_number, c.email AS email, c.civil_id AS civil_id\n",
    "                    ORDER BY similarity_score DESC\n",
    "                    \"\"\"\n",
    "\n",
    "        # Prepare similarity query for the name\n",
    "        if name is not None and phone == None and civil_id == None and email == None:\n",
    "            name_result = graph.query(name_query, {\n",
    "                'name': name\n",
    "            })\n",
    "\n",
    "            if name_result:\n",
    "                return f\"The given Name is associated with the customer {name_result[0]['customer_name']}. Are you looking for this customer? or want to create a new lead?\"\n",
    "            else:\n",
    "               return f\"{name} is not available or no matching result found for the given Name.\"\n",
    "\n",
    "        # Prepare phone query\n",
    "        if phone:\n",
    "            phone_query = \"\"\"\n",
    "            MATCH (c:Lead)\n",
    "            WHERE c.phone_number = $phone \n",
    "            RETURN c.name AS customer_name, c.phone_number AS phone_number, c.email AS email, c.civil_id AS civil_id\n",
    "            \"\"\"\n",
    "            cypher_queries.append((\"phone number\", phone_query))\n",
    "\n",
    "        # Prepare civil ID query\n",
    "        if civil_id:\n",
    "            civil_id_query = \"\"\"\n",
    "            MATCH (c:Lead) \n",
    "            WHERE c.civil_id = $civil_id \n",
    "            RETURN c.name AS customer_name, c.phone_number AS phone_number, c.email AS email, c.civil_id AS civil_id\n",
    "            \"\"\"\n",
    "            cypher_queries.append((\"civil-id\", civil_id_query))\n",
    "\n",
    "        # Prepare email query\n",
    "        if email:\n",
    "            email_query = \"\"\"\n",
    "            MATCH (c:Lead) \n",
    "            WHERE c.email = $email \n",
    "            RETURN c.name AS customer_name, c.phone_number AS phone_number, c.email AS email, c.civil_id AS civil_id\n",
    "            \"\"\"\n",
    "            cypher_queries.append((\"e-mail\", email_query))\n",
    "\n",
    "        # Execute each semi-verified query\n",
    "        for query_type, query in cypher_queries:\n",
    "            db_result = graph.query(query, {\n",
    "                'name': name,\n",
    "                'phone': phone,\n",
    "                'civil_id': civil_id,\n",
    "                'email': email\n",
    "            })\n",
    "            # print(db_result)\n",
    "            # Check if the query returned any results\n",
    "            if db_result:\n",
    "                semi_verified_result.append(f\"I see that the {query_type} you provided is associated with {db_result[0]['customer_name']}. Could you please provide the {query_type} for {name}?\"\n",
    ")\n",
    "            else:\n",
    "                semi_verified_result.append(f\"I was unable to locate the {query_type} in our system. Would you like me to proceed with creating a new lead?\")\n",
    "\n",
    "        for results in set(semi_verified_result):\n",
    "            print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lead_name': 'Tamil', 'phone_number': '1111111111', 'civil_id': None, 'email': None, 'lead_id': None}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"A customer named 'tamil' already exists in our system. Would you like to continue with this existing customer, or should I create a new customer?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_lead(\n",
    "    name=\"tamil\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, scrolledtext\n",
    "\n",
    "class ProjectStructure:\n",
    "    def __init__(self, startpath, ignore_dirs=None, ignore_files=None):\n",
    "        self.startpath = startpath\n",
    "        self.ignore_dirs = ignore_dirs if ignore_dirs is not None else ['.git', '__pycache__', 'node_modules']\n",
    "        self.ignore_files = ignore_files if ignore_files is not None else ['*.pyc', '*.log', '*.tmp', '*.swp']\n",
    "\n",
    "    def list_files(self):\n",
    "        file_tree = []\n",
    "        try:\n",
    "            for root, dirs, files in os.walk(self.startpath):\n",
    "                # Filter out ignored directories\n",
    "                dirs[:] = [d for d in dirs if d not in self.ignore_dirs]\n",
    "                # Filter out ignored files\n",
    "                files = [f for f in files if not any(f.endswith(ext) for ext in self.ignore_files)]\n",
    "\n",
    "                level = root.replace(self.startpath, '').count(os.sep)\n",
    "                indent = ' '*  4 *level\n",
    "                file_tree.append(f'{indent}{os.path.basename(root)}/')\n",
    "                subindent = ' '*  4 * (level + 1)\n",
    "                for f in files:\n",
    "                    file_tree.append(f'{subindent}{f}')\n",
    "        except Exception as e:\n",
    "            file_tree.append(f\"Error occurred: {e}\")\n",
    "        return \"\\n\".join(file_tree)\n",
    "\n",
    "class App:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Project Folder Structure\")\n",
    "        self.root.attributes('-fullscreen', True)  # Open in full screen\n",
    "        \n",
    "        # Disable default close button\n",
    "        self.root.protocol(\"WM_DELETE_WINDOW\", self.disable_close)\n",
    "        \n",
    "        # Decorative background\n",
    "        self.bg_color = \"#f0f8ff\"\n",
    "        self.root.configure(bg=self.bg_color)\n",
    "        \n",
    "        # Apply a custom font and styling\n",
    "        self.font = ('Arial', 12)\n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        # Custom title bar\n",
    "        self.title_bar = tk.Frame(self.root, bg=\"#4682b4\", relief=\"raised\", bd=2)\n",
    "        self.title_bar.pack(fill=tk.X)\n",
    "\n",
    "        # Minimize, Maximize, Close buttons\n",
    "        self.minimize_button = tk.Button(self.title_bar, text=\"_\", command=self.minimize_window, bg=\"#87cefa\", fg=\"black\", font=self.font)\n",
    "        self.minimize_button.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.maximize_button = tk.Button(self.title_bar, text=\"☐\", command=self.maximize_window, bg=\"#87cefa\", fg=\"black\", font=self.font)\n",
    "        self.maximize_button.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.close_button = tk.Button(self.title_bar, text=\"X\", command=self.close_window, bg=\"#ff6347\", fg=\"black\", font=self.font)\n",
    "        self.close_button.pack(side=tk.RIGHT, padx=5)\n",
    "        \n",
    "        # Path entry\n",
    "        self.path_label = tk.Label(self.root, text=\"Select Project Folder:\", bg=self.bg_color, font=self.font, padx=10, pady=5)\n",
    "        self.path_label.pack(pady=10)\n",
    "\n",
    "        self.path_entry = tk.Entry(self.root, width=60, font=self.font)\n",
    "        self.path_entry.pack(pady=5)\n",
    "\n",
    "        self.browse_button = tk.Button(self.root, text=\"Browse\", command=self.browse_folder, font=self.font, bg=\"#87cefa\", fg=\"black\")\n",
    "        self.browse_button.pack(pady=5)\n",
    "\n",
    "        self.show_button = tk.Button(self.root, text=\"Show Structure\", command=self.show_structure, font=self.font, bg=\"#87cefa\", fg=\"black\")\n",
    "        self.show_button.pack(pady=10)\n",
    "\n",
    "        # Text area to show file structure\n",
    "        self.text_area = scrolledtext.ScrolledText(self.root, wrap=tk.WORD, height=20, width=80, font=self.font, bg=\"#ffffff\", fg=\"black\")\n",
    "        self.text_area.pack(pady=10, padx=10)\n",
    "\n",
    "    def browse_folder(self):\n",
    "        folder_path = filedialog.askdirectory()\n",
    "        if folder_path:\n",
    "            self.path_entry.delete(0, tk.END)\n",
    "            self.path_entry.insert(0, folder_path)\n",
    "\n",
    "    def show_structure(self):\n",
    "        path = self.path_entry.get()\n",
    "        if os.path.isdir(path):\n",
    "            project_structure = ProjectStructure(path)\n",
    "            structure = project_structure.list_files()\n",
    "            self.text_area.delete(1.0, tk.END)\n",
    "            self.text_area.insert(tk.END, structure)\n",
    "        else:\n",
    "            self.text_area.delete(1.0, tk.END)\n",
    "            self.text_area.insert(tk.END, \"Invalid directory path.\")\n",
    "    \n",
    "    def disable_close(self):\n",
    "        pass  # Do nothing on close attempt\n",
    "\n",
    "    def minimize_window(self):\n",
    "        self.root.iconify()\n",
    "\n",
    "    def maximize_window(self):\n",
    "        self.root.attributes('-fullscreen', not self.root.attributes('-fullscreen'))\n",
    "\n",
    "    def close_window(self):\n",
    "        self.root.destroy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = App(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding 'update_flight': ['assistant', 'book_hotel', 'update_flight']\n",
      "After popping the last action: ['assistant', 'book_hotel']\n",
      "After passing None: ['assistant', 'book_hotel']\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "# Function to update the dialog stack\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Update the dialog stack based on the new action.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "# Test the function\n",
    "if __name__ == \"__main__\":\n",
    "    # Initial dialog stack\n",
    "    stack = [\"assistant\", \"book_hotel\"]\n",
    "\n",
    "    # Add an action\n",
    "    new_stack = update_dialog_stack(stack, \"update_flight\")\n",
    "    print(\"After adding 'update_flight':\", new_stack)\n",
    "\n",
    "    # Remove the last action\n",
    "    new_stack = update_dialog_stack(new_stack, \"pop\")\n",
    "    print(\"After popping the last action:\", new_stack)\n",
    "\n",
    "    # No change (passing None)\n",
    "    new_stack = update_dialog_stack(new_stack, None)\n",
    "    print(\"After passing None:\", new_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Car rental assistant\n",
    "\n",
    "builder.add_node(\n",
    "    \"enter_book_car_rental\",\n",
    "    create_entry_node(\"Car Rental Assistant\", \"book_car_rental\"),\n",
    ")\n",
    "builder.add_node(\"book_car_rental\", Assistant(book_car_rental_runnable))\n",
    "builder.add_edge(\"enter_book_car_rental\", \"book_car_rental\")\n",
    "builder.add_node(\n",
    "    \"book_car_rental_safe_tools\",\n",
    "    create_tool_node_with_fallback(book_car_rental_safe_tools),\n",
    ")\n",
    "builder.add_node(\n",
    "    \"book_car_rental_sensitive_tools\",\n",
    "    create_tool_node_with_fallback(book_car_rental_sensitive_tools),\n",
    ")\n",
    "\n",
    "\n",
    "def route_book_car_rental(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"book_car_rental_safe_tools\",\n",
    "    \"book_car_rental_sensitive_tools\",\n",
    "    \"leave_skill\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    did_cancel = any(tc[\"name\"] == CompleteOrEscalate.__name__ for tc in tool_calls)\n",
    "    if did_cancel:\n",
    "        return \"leave_skill\"\n",
    "    safe_toolnames = [t.name for t in book_car_rental_safe_tools]\n",
    "    if all(tc[\"name\"] in safe_toolnames for tc in tool_calls):\n",
    "        return \"book_car_rental_safe_tools\"\n",
    "    return \"book_car_rental_sensitive_tools\"\n",
    "\n",
    "\n",
    "builder.add_edge(\"book_car_rental_sensitive_tools\", \"book_car_rental\")\n",
    "builder.add_edge(\"book_car_rental_safe_tools\", \"book_car_rental\")\n",
    "builder.add_conditional_edges(\"book_car_rental\", route_book_car_rental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_existence_verification(\n",
    "    name: Annotated[Optional[str],\"Customer name in lower case\"],\n",
    "    email: Annotated[Optional[str],\"Customer email in lower case\"], \n",
    "    phone: Annotated[Optional[str],\"Customer phone number in 10 digits\"],\n",
    "    civil_id: Annotated[Optional[str],\"Customer civil ID in 12 digits\"],):\n",
    "    \n",
    "    \n",
    "    # Base query for fully verified search\n",
    "    \"\"\"\n",
    "    Tool to check the customer existence before proceeding to lead creation.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the customer to search for.\n",
    "        email (str): The email of the customer to search for.\n",
    "        phone (str): The phone number of the customer to search for.\n",
    "        civil_id (str): The civil ID of the customer to search for.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries containing the search results. Each dictionary\n",
    "        contains the name, phone number, email, civil ID, and ID of the lead.\n",
    "    \"\"\"\n",
    "    def validation():\n",
    "        phone_validation = True\n",
    "        civil_validation = True\n",
    "        email_validation = True\n",
    "\n",
    "        if phone:\n",
    "            phone_validation = validate_phone_number(phone)\n",
    "            if phone_validation is not True:\n",
    "                return phone_validation\n",
    "        \n",
    "        if civil_id:\n",
    "            civil_validation = validate_civil_id(civil_id)\n",
    "            if civil_validation is not True:\n",
    "                return civil_validation\n",
    "        \n",
    "        if email:\n",
    "            email_validation = validate_email_address(email)\n",
    "            if email_validation is not True:\n",
    "                return email_validation\n",
    "\n",
    "        # If all validations pass, return True\n",
    "        return all([phone_validation, civil_validation, email_validation])\n",
    "\n",
    "    validated = validation()\n",
    "\n",
    "    if validated == True:\n",
    "\n",
    "        name_query = \"\"\"\n",
    "                    MATCH (c:Lead)\n",
    "                    WITH c, apoc.text.levenshteinSimilarity(toLower(c.name), toLower($name)) AS similarity_score\n",
    "                    WHERE similarity_score > 0.5\n",
    "                    RETURN c.name AS customer_name, c.phone_number AS phone_number, c.email AS email, c.civil_id AS civil_id\n",
    "                    ORDER BY similarity_score DESC\n",
    "                    \"\"\"\n",
    "\n",
    "        name_contains_query = \"\"\"\n",
    "                    MATCH (c:Lead)\n",
    "                    WHERE toLower(c.name) CONTAINS toLower($name)\n",
    "                    RETURN c.name AS customer_name, \n",
    "                        c.phone_number AS phone_number, \n",
    "                        c.email AS email, \n",
    "                        c.civil_id AS civil_id\n",
    "                    \"\"\"\n",
    "        both_query = \"\"\"MATCH (c:Lead)\n",
    "                        WHERE toLower(c.name) CONTAINS toLower($name)\n",
    "                        WITH c\n",
    "                        WITH c, apoc.text.levenshteinSimilarity(toLower(c.name), toLower($name)) AS similarity_score\n",
    "                        WHERE similarity_score > 0.6\n",
    "                        RETURN c.name AS customer_name, \n",
    "                            c.phone_number AS phone_number, \n",
    "                            c.email AS email, \n",
    "                            c.civil_id AS civil_id\n",
    "                        ORDER BY similarity_score DESC\n",
    "                        \"\"\"    \n",
    "\n",
    "        if name and all(x is None for x in (phone, civil_id, email)):\n",
    "\n",
    "            name_result = graph.query(name_query, {'name': name})\n",
    "            name_contains_result = graph.query(name_contains_query, {'name': name})\n",
    "            both_result = graph.query(both_query, {'name': name})\n",
    "\n",
    "            if name_result:\n",
    "                return ToolMessage(f\"The provided Name is associated with the following customer(s): {[entry['customer_name'] for entry in name_result]}. Would you like to proceed with one of these customers, or would you prefer to create a new lead?\")        \n",
    "            else:\n",
    "                return ToolMessage(f\"No matching results were found for the name '{name}'. Please review or confirm the provided details. Would you like to create a new lead instead?\")\n",
    "\n",
    "        else:\n",
    "            query = \"\"\"\n",
    "            MATCH (l:Lead)\n",
    "            WHERE toLower(l.name) = toLower($name)\n",
    "            \"\"\"\n",
    "            conditions = []\n",
    "            if phone:\n",
    "                conditions.append(\"l.phone_number = $phone\")\n",
    "            if civil_id:\n",
    "                conditions.append(\"l.civil_id = $civil_id\")\n",
    "            if email:\n",
    "                conditions.append(\"l.email = $email\")\n",
    "            \n",
    "            if conditions:\n",
    "                query += \" AND \" + \" AND \".join(conditions)\n",
    "\n",
    "            query += \"\"\"\n",
    "            RETURN l.name AS lead_name, l.phone_number AS phone_number, l.civil_id AS civil_id, l.email AS email, l.id AS lead_id\n",
    "            \"\"\"        \n",
    "            verified_result = graph.query(query, {\n",
    "                'name': name,\n",
    "                'phone': phone,\n",
    "                'civil_id': civil_id,\n",
    "                'email': email\n",
    "            })\n",
    "\n",
    "            if verified_result:\n",
    "                return ToolMessage(f\"A customer named '{name}' already exists in our system with matching details (Phone: {verified_result[0]['phone_number']}, Email: {verified_result[0]['email']}, Civil ID: {verified_result[0]['civil_id']}). Would you like to proceed with this customer, or create a new lead?\")\n",
    "            \n",
    "            else:        \n",
    "                cypher_queries = []\n",
    "                semi_verified_result = []\n",
    "\n",
    "                if phone:\n",
    "                    phone_query = \"\"\"\n",
    "                    MATCH (c:Lead)\n",
    "                    WHERE c.phone_number = $phone \n",
    "                    RETURN c.name AS customer_name, c.phone_number AS phone_number, c.email AS email, c.civil_id AS civil_id\n",
    "                    \"\"\"\n",
    "                    cypher_queries.append((\"phone number\", phone_query))\n",
    "\n",
    "                if civil_id:\n",
    "                    civil_id_query = \"\"\"\n",
    "                    MATCH (c:Lead) \n",
    "                    WHERE c.civil_id = $civil_id \n",
    "                    RETURN c.name AS customer_name, c.phone_number AS phone_number, c.email AS email, c.civil_id AS civil_id\n",
    "                    \"\"\"\n",
    "                    cypher_queries.append((\"civil ID\", civil_id_query))\n",
    "\n",
    "                if email:\n",
    "                    email_query = \"\"\"\n",
    "                    MATCH (c:Lead) \n",
    "                    WHERE c.email = $email \n",
    "                    RETURN c.name AS customer_name, c.phone_number AS phone_number, c.email AS email, c.civil_id AS civil_id\n",
    "                    \"\"\"\n",
    "                    cypher_queries.append((\"email\", email_query))\n",
    "\n",
    "                for query_type, query in cypher_queries:\n",
    "                    db_result = graph.query(query, {\n",
    "                        'name': name,\n",
    "                        'phone': phone,\n",
    "                        'civil_id': civil_id,\n",
    "                        'email': email\n",
    "                    })\n",
    "\n",
    "                    if db_result:\n",
    "                        return ToolMessage(f\"I have identified that the {query_type} you provided is associated with {db_result[0]['customer_name']}. Could you please confirm or provide the correct {query_type} for {name}?\")\n",
    "\n",
    "                    else:\n",
    "                        return ToolMessage(f\"I was unable to locate the {query_type} ({phone if query_type == 'phone number' else civil_id if query_type == 'civil ID' else email}) in our system. Would you like to proceed with creating a new lead?\")\n",
    "    else:return validated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
